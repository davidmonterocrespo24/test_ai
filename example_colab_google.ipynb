{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMc2bcYiFL9TvZnremYN3/Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/davidmonterocrespo24/test_ai/blob/main/example_colab_google.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Para entrenar un modelo de lenguaje GPT-2 en Python usando el código de una carpeta, necesitarás seguir los siguientes pasos:\n",
        "\n",
        "Instalar las dependencias necesarias:"
      ],
      "metadata": {
        "id": "ImSdKZbPObA2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6QWpLsteOV5H"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow==2.3.0\n",
        "!pip install tensorflow_datasets==3.2.1\n",
        "!pip install transformers==3.5.1"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Importar las bibliotecas necesarias:\n"
      ],
      "metadata": {
        "id": "WYPzgk1ZOfFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import tensorflow_datasets as tfds\n",
        "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
        "import os\n"
      ],
      "metadata": {
        "id": "praBxQrgOhtx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Cargar los datos:"
      ],
      "metadata": {
        "id": "AIgFPUlHOjzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path = 'modelo'\n",
        "text = ''\n",
        "for filename in os.listdir(path):\n",
        "    with open(os.path.join(path, filename), 'r') as f:\n",
        "        text += f.read()\n"
      ],
      "metadata": {
        "id": "pU5ZoEGXOlO4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tokenizar los datos:"
      ],
      "metadata": {
        "id": "axuE8EG5OpeU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Cargar el modelo y el tokenizador\n",
        "model = TFGPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id)\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Ajustar la longitud máxima de secuencia\n",
        "model.config.max_position_embeddings = 102048\n",
        "tokenizer.model_max_length = 102048\n",
        "tokenized_text = tokenizer.encode(text)"
      ],
      "metadata": {
        "id": "QGlwg5z5Onqy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Crear los conjuntos de entrenamiento y prueba:"
      ],
      "metadata": {
        "id": "jaAknmeiOtAf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "examples = []\n",
        "block_size = 100\n",
        "BATCH_SIZE = 12\n",
        "BUFFER_SIZE = 1000\n",
        "for i in range(0, len(tokenized_text)-block_size+1, block_size):\n",
        "    examples.append(tokenized_text[i:i+block_size])\n",
        "inputs, labels = [], []\n",
        "for ex in examples:\n",
        "    inputs.append(ex[:-1])\n",
        "    labels.append(ex[1:])\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inputs, labels))\n",
        "dataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)\n"
      ],
      "metadata": {
        "id": "Nhe91aqiOvae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Definir el modelo:\n"
      ],
      "metadata": {
        "id": "jQN1X1kPOxHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = TFGPT2LMHeadModel.from_pretrained('gpt2', pad_token_id=tokenizer.eos_token_id)\n"
      ],
      "metadata": {
        "id": "HBPqXr1gOy9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Compilar el modelo:"
      ],
      "metadata": {
        "id": "yCNBUxI1O2Me"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)\n",
        "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=3e-5, epsilon=1e-08, clipnorm=1.0), loss=[loss_fn, *[None] * model.config.n_layer])\n"
      ],
      "metadata": {
        "id": "sp0Pe2FFO0h7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Entrenar el modelo:"
      ],
      "metadata": {
        "id": "nNNpBozBO8mV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 1\n",
        "model.fit(dataset, epochs=EPOCHS)"
      ],
      "metadata": {
        "id": "bnQOz7HeO9u6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Guardar el modelo:"
      ],
      "metadata": {
        "id": "wFWE5I9hPDwQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save_pretrained('modelo')"
      ],
      "metadata": {
        "id": "DtUSy_oiPANS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Aquí te muestro un ejemplo de cómo utilizar el modelo entrenado anteriormente para generar texto:"
      ],
      "metadata": {
        "id": "HvtAkRi-PIXa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from transformers import GPT2Tokenizer, TFGPT2LMHeadModel\n",
        "\n",
        "# Cargar el modelo y el tokenizador\n",
        "model = TFGPT2LMHeadModel.from_pretrained('modelo')\n",
        "tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\n",
        "# Generar texto\n",
        "prompt = \"En un lugar de la Mancha\"\n",
        "input_ids = tokenizer.encode(prompt, return_tensors='tf')\n",
        "output = model.generate(input_ids, max_length=100, do_sample=True, top_k=50)\n",
        "generated_text = tokenizer.decode(output[0], skip_special_tokens=True)\n",
        "\n",
        "print(generated_text)\n"
      ],
      "metadata": {
        "id": "2I1Fk5R1PLEu"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}